{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "zJ17XXkFiRbC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import daily_dialogue\n",
    "import glob\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "import random\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from IPython.display import HTML\n",
    "from time import gmtime, strftime\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1523874588473,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "LC34tx28ia2C",
    "outputId": "4df32e2b-cbc8-40d3-dd7e-9bcd469da26c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150946\n",
      "['of', 'course', ',', 'this', 'is', 'my', 'first', 'time', 'here', '.', 'my', 'mom', 'has', 'a', 'membership', 'here', '.', 'here', 'is', 'the', 'card', '.', '<EOS>']\n",
      "['<START>', 'okay', 'then', '.', 'you', 'are', 'the', 'younger', 'customer', 'here', 'ever', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "data_X, data_Y, max_dialogue_len = daily_dialogue.create_dataset()\n",
    "print (len(data_X))\n",
    "print (data_X[1])\n",
    "print (data_Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1523874588812,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "qlzcG2AAiein",
    "outputId": "71645a98-f4da-438c-96b5-7165e34ee6c1"
   },
   "outputs": [],
   "source": [
    "def get_unique_words(data_X, data_Y):\n",
    "    unique_words = []\n",
    "\n",
    "    for index in range(len(data_X)):\n",
    "        unique_words.extend(set(data_X[index] + data_Y[index]))\n",
    "\n",
    "    unique_words = list(set(unique_words))\n",
    "    unique_words = [\"<PAD>\"] + unique_words\n",
    "\n",
    "    return unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1523874588812,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "qlzcG2AAiein",
    "outputId": "71645a98-f4da-438c-96b5-7165e34ee6c1"
   },
   "outputs": [],
   "source": [
    "def build_vocabs(unique_words):\n",
    "    word2idx = {value:index for index, value in enumerate(unique_words)}\n",
    "    idx2word = {index:value for index, value in enumerate(unique_words)}\n",
    "    \n",
    "    return word2idx, idx2word, len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1523874588812,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "qlzcG2AAiein",
    "outputId": "71645a98-f4da-438c-96b5-7165e34ee6c1"
   },
   "outputs": [],
   "source": [
    "# unique_words = get_unique_words(data_X, data_Y)\n",
    "# with open(\"aug_unique_words.p\", \"wb\") as pickle_d:\n",
    "#     pickle.dump(unique_words, pickle_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 258,
     "status": "ok",
     "timestamp": 1523874588812,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "qlzcG2AAiein",
    "outputId": "71645a98-f4da-438c-96b5-7165e34ee6c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24043 906 0 11676 17782\n"
     ]
    }
   ],
   "source": [
    "unique_words = pickle.load(open('aug_unique_words.p', 'rb'))\n",
    "word2idx, idx2word, vocab_size = build_vocabs(unique_words)\n",
    "print (vocab_size, word2idx[\"<START>\"], word2idx[\"<PAD>\"], word2idx[\"<EOS>\"], word2idx[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "wXlJb-FUihV1"
   },
   "outputs": [],
   "source": [
    "train_X, train_Y = data_X[:145000], data_Y[:145000]\n",
    "test_X, test_Y = data_X[145000:], data_Y[145000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UL7h2_zcij1n"
   },
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, lengths, batch_size):\n",
    "    max_len = max(lengths)\n",
    "    for i in range (batch_size):\n",
    "        diff = max_len - lengths[i]\n",
    "        sequences[i] += [word2idx[\"<PAD>\"]] * diff\n",
    "\n",
    "    return np.asarray(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "UL7h2_zcij1n"
   },
   "outputs": [],
   "source": [
    "def batch_data(X, Y, batch_size):\n",
    "    start = 0\n",
    "    while start + batch_size <= len(X):\n",
    "        enc_batch_input = list()\n",
    "        dec_batch_input = list()\n",
    "        dec_batch_target = list()\n",
    "        enc_inp_lens = list()\n",
    "        dec_inp_lens = list()\n",
    "        target_w = list()\n",
    "        for index in range(start, start + batch_size):\n",
    "            batch_index = index - start\n",
    "\n",
    "            enc_batch_input.append([])\n",
    "            for word_index, word in enumerate(X[index]):\n",
    "                enc_batch_input[-1].append(word2idx[word])\n",
    "            enc_inp_lens.append(len(enc_batch_input[-1]))\n",
    "\n",
    "            dec_batch_input.append([])\n",
    "            for word_index, word in enumerate(Y[index][:-1]):\n",
    "                dec_batch_input[-1].append(word2idx[word])\n",
    "            dec_inp_lens.append(len(dec_batch_input[-1]))\n",
    "\n",
    "            dec_batch_target.append([])\n",
    "            for word_index, word in enumerate(Y[index][1:]):\n",
    "                dec_batch_target[-1].append(word2idx[word])\n",
    "        \n",
    "        for batch_i in range(batch_size):\n",
    "            pad = [1] * dec_inp_lens[batch_i]\n",
    "            diff = max(dec_inp_lens) - dec_inp_lens[batch_i]\n",
    "            pad.extend([0] * diff)\n",
    "            target_w.append(pad)\n",
    "\n",
    "        enc_batch_input = pad_sequences(enc_batch_input, enc_inp_lens, batch_size)\n",
    "        dec_batch_input = pad_sequences(dec_batch_input, dec_inp_lens, batch_size)\n",
    "        dec_batch_target = pad_sequences(dec_batch_target, dec_inp_lens, batch_size)\n",
    "\n",
    "        enc_inp_lens = np.asarray(enc_inp_lens)\n",
    "        dec_inp_lens = np.asarray(dec_inp_lens)\n",
    "        target_w = np.asarray(target_w)\n",
    "\n",
    "        yield enc_batch_input, dec_batch_input, dec_batch_target, enc_inp_lens, dec_inp_lens, target_w\n",
    "        \n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "cZN_4cdUimwo"
   },
   "outputs": [],
   "source": [
    "input_num_units = 128\n",
    "decoder_num_units = 256\n",
    "\n",
    "assert input_num_units*2 == decoder_num_units\n",
    "\n",
    "keep_prob = 0.75\n",
    "embedding_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1523874593170,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "FYwMbbSviov2",
    "outputId": "d70ad5d3-6144-4dd4-81ab-31091aee0fd2"
   },
   "outputs": [],
   "source": [
    "# dont run for demo\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True))\n",
    "\n",
    "encoder_inputs = tf.placeholder(tf.int32, [None, None], 'encoder_inputs')\n",
    "decoder_inputs = tf.placeholder(tf.int32, [None, None], 'decoder_inputs')\n",
    "decoder_targets = tf.placeholder(tf.int32, [None, None], 'decoder_targets')\n",
    "encoder_lengths = tf.placeholder(tf.int32, [None], 'encoder_lengths')\n",
    "decoder_lengths = tf.placeholder(tf.int32, [None], 'decoder_lengths')\n",
    "target_weights = tf.placeholder(tf.float32, [None, None], 'target_weights')\n",
    "learning_rate = tf.placeholder(tf.float32, [], 'learning_rate')\n",
    "batch_size = tf.placeholder(tf.int32, [], 'batch_size')\n",
    "\n",
    "# Embedding\n",
    "with tf.variable_scope(\"embeddings\"):\n",
    "    embedding_encoder = tf.get_variable(\n",
    "        \"embedding_encoder\", [vocab_size, embedding_size])\n",
    "\n",
    "    encoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, encoder_inputs)\n",
    "\n",
    "    decoder_emb_inp = tf.nn.embedding_lookup(\n",
    "        embedding_encoder, decoder_inputs)\n",
    "\n",
    "# Encoder (dynamic, bi-directional network)\n",
    "with tf.variable_scope('encoder_lstm'):\n",
    "    enc_fw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        input_num_units, state_is_tuple=True, name=\"enc_fw\")\n",
    "    \n",
    "    enc_bw_cell = tf.nn.rnn_cell.BasicLSTMCell(\n",
    "        input_num_units, state_is_tuple=True, name=\"enc_bw\")\n",
    "    \n",
    "    enc_fw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        enc_fw_cell, input_keep_prob = keep_prob)\n",
    "    \n",
    "    enc_bw_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        enc_bw_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "    enc_bi_outputs, encoder_state = tf.nn.bidirectional_dynamic_rnn(enc_fw_cell, enc_bw_cell, \\\n",
    "                                                                encoder_emb_inp, \\\n",
    "                                                                sequence_length=encoder_lengths, \\\n",
    "                                                                time_major=False, dtype=tf.float32)\n",
    "    encoder_outputs = tf.concat(enc_bi_outputs, -1)\n",
    "\n",
    "# Decoder with attention mechanism\n",
    "with tf.variable_scope('decoder_lstm'):\n",
    "    total_c_state = tf.concat(axis=1,values=[encoder_state[0].c, encoder_state[1].c])\n",
    "    total_h_state = tf.concat(axis=1,values=[encoder_state[0].h, encoder_state[1].h])\n",
    "\n",
    "    total_state = tf.contrib.rnn.LSTMStateTuple(total_c_state, total_h_state)\n",
    "\n",
    "    decoder_cell = tf.nn.rnn_cell.BasicLSTMCell(decoder_num_units, state_is_tuple=True, name=\"dec_lstm\")\n",
    "    \n",
    "    decoder_cell = tf.contrib.rnn.DropoutWrapper(\n",
    "        decoder_cell, input_keep_prob = keep_prob)\n",
    "\n",
    "    projection_layer = tf.layers.Dense(\n",
    "        vocab_size, use_bias=False)\n",
    "\n",
    "    attention_states = encoder_outputs\n",
    "\n",
    "    attention_mechanism = tf.contrib.seq2seq.LuongAttention(\n",
    "        decoder_num_units, attention_states,\n",
    "        memory_sequence_length=decoder_lengths)\n",
    "    \n",
    "    decoder_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "        decoder_cell, attention_mechanism,\n",
    "        attention_layer_size=decoder_num_units)\n",
    "    \n",
    "    initial_state = decoder_cell.zero_state(dtype = tf.float32, batch_size=batch_size)\n",
    "    initial_state = initial_state.clone(cell_state=total_state)\n",
    "\n",
    "    helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "        decoder_emb_inp, decoder_lengths)\n",
    "\n",
    "    decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        decoder_cell, helper, initial_state,\n",
    "        output_layer=projection_layer)\n",
    "\n",
    "    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n",
    "\n",
    "    logits = decoder_outputs.rnn_output\n",
    "\n",
    "with tf.variable_scope('loss'):\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=decoder_targets, logits=logits)\n",
    "\n",
    "    train_loss = tf.reduce_sum(loss * target_weights)\n",
    "\n",
    "with tf.variable_scope('optimization'):\n",
    "    max_gradient_norm = 1\n",
    "    params = tf.trainable_variables()\n",
    "    gradients = tf.gradients(train_loss, params)\n",
    "    clipped_gradients, _ = tf.clip_by_global_norm(\n",
    "        gradients, max_gradient_norm)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    update_step = optimizer.apply_gradients(\n",
    "        zip(clipped_gradients, params))\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "CmTA39mMAteQ"
   },
   "outputs": [],
   "source": [
    "# dont run for demo\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "kEkzwGFw9JFz"
   },
   "outputs": [],
   "source": [
    "# dont run for demo\n",
    "num_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 951,
     "status": "error",
     "timestamp": 1523874846032,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "NR0pX3Q0irGp",
    "outputId": "4aea0647-5e47-4862-9dbd-83438d65b509"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  3.35it/s]\u001b[A\n",
      "2it [00:00,  2.58it/s]\u001b[A\n",
      "1870it [14:27,  2.15it/s]"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[50,205,24043] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder_lstm/decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder_lstm/decoder/TensorArrayStack/TensorArrayGatherV3, decoder_lstm/decoder/concat_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: optimization/gradients/decoder_lstm/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1063_.../cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopoptimization/gradients/Switch_8/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'decoder_lstm/decoder/transpose', defined at:\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-3de848bfc45d>\", line 79, in <module>\n    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 324, in dynamic_decode\n    final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 459, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 459, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 74, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1453, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5658, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,205,24043] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder_lstm/decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder_lstm/decoder/TensorArrayStack/TensorArrayGatherV3, decoder_lstm/decoder/concat_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: optimization/gradients/decoder_lstm/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1063_.../cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopoptimization/gradients/Switch_8/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    517\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,205,24043] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder_lstm/decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder_lstm/decoder/TensorArrayStack/TensorArrayGatherV3, decoder_lstm/decoder/concat_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: optimization/gradients/decoder_lstm/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1063_.../cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopoptimization/gradients/Switch_8/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4684666dbdd2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m              \u001b[0mtarget_weights\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtarget_w\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m              \u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m              batch_size: bs})\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1374\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[50,205,24043] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder_lstm/decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder_lstm/decoder/TensorArrayStack/TensorArrayGatherV3, decoder_lstm/decoder/concat_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: optimization/gradients/decoder_lstm/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1063_.../cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopoptimization/gradients/Switch_8/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'decoder_lstm/decoder/transpose', defined at:\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-3de848bfc45d>\", line 79, in <module>\n    decoder_outputs, _, _ = tf.contrib.seq2seq.dynamic_decode(decoder)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/contrib/seq2seq/python/ops/decoder.py\", line 324, in dynamic_decode\n    final_outputs = nest.map_structure(_transpose_batch_time, final_outputs)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 459, in map_structure\n    structure[0], [func(*x) for x in entries])\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/util/nest.py\", line 459, in <listcomp>\n    structure[0], [func(*x) for x in entries])\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\", line 74, in _transpose_batch_time\n    ([1, 0], math_ops.range(2, x_rank)), axis=0))\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1453, in transpose\n    ret = transpose_fn(a, perm, name=name)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5658, in transpose\n    \"Transpose\", x=x, perm=perm, name=name)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3271, in create_op\n    op_def=op_def)\n  File \"/home/pritish/anaconda2/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1650, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[50,205,24043] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: decoder_lstm/decoder/transpose = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](decoder_lstm/decoder/TensorArrayStack/TensorArrayGatherV3, decoder_lstm/decoder/concat_2)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: optimization/gradients/decoder_lstm/decoder/while/BasicDecoderStep/TrainingHelperNextInputs/cond/Merge_grad/cond_grad/_173 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1063_.../cond_grad\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](^_cloopoptimization/gradients/Switch_8/_1)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "# dont run for demo\n",
    "# Training\n",
    "epochs = 20\n",
    "bs = 50\n",
    "for epoch_i in range(epochs):\n",
    "    if epoch_i < 3:\n",
    "        lr = 0.01\n",
    "    elif epoch_i >= 3 and epoch_i < 6:\n",
    "        lr = 0.005\n",
    "    elif epoch_i >= 7 and epoch_i < 10:\n",
    "        lr = 0.001\n",
    "    elif epoch_i >= 11 and epoch_i < 14:\n",
    "        lr = 0.0005\n",
    "    elif epoch_i >= 15 and epoch_i < epochs:\n",
    "        lr = 0.0001\n",
    "    start_time = time.time()\n",
    "    for batch_i, (enc_batch_inputs, dec_batch_inputs, dec_batch_targets, enc_inp_lens, dec_inp_lens, target_w) \\\n",
    "                in enumerate(tqdm(batch_data(train_X, train_Y, bs))):\n",
    "\n",
    "        _, batch_loss, batch_logits = sess.run([update_step, train_loss, logits],\n",
    "            feed_dict = {encoder_inputs: enc_batch_inputs,\n",
    "             decoder_inputs: dec_batch_inputs,\n",
    "             decoder_targets: dec_batch_targets,\n",
    "             encoder_lengths: enc_inp_lens,\n",
    "             decoder_lengths: dec_inp_lens,\n",
    "             target_weights: target_w,\n",
    "             learning_rate: lr,\n",
    "             batch_size: bs})\n",
    "        \n",
    "    num_epochs += 1\n",
    "    accuracy = np.mean(batch_logits.argmax(axis=-1) == dec_batch_targets)\n",
    "    print('Epoch:', epoch_i+1, 'Loss:', batch_loss/bs, 'Accuracy:', accuracy, 'Epoch duration:', (time.time() - start_time), 's')\n",
    "    saver.save(sess, './mod_checkpoints/epoch'+str(num_epochs)+\"_\"+str(strftime(\"%Y-%m-%d_%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OY91jf6VixKv"
   },
   "outputs": [],
   "source": [
    "def num2sent(pred, mode, seq_len=None):\n",
    "    res = \"\"\n",
    "    if mode == \"i\":\n",
    "        pred = np.flip(pred, 0)\n",
    "        pred = pred[-seq_len:-1]        \n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    elif mode == \"r\":\n",
    "        pred = pred[1:-1]\n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    elif mode == \"t\":\n",
    "        pred = pred[:-1]\n",
    "        for idx in pred:\n",
    "            res += idx2word[idx] + \" \"\n",
    "    return res, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_sample(test_sess, ques, ques_len, bs=1):\n",
    "    dec_input = np.zeros((1, 1)) + word2idx['<START>']\n",
    "    dec_len = [1]\n",
    "    while dec_input[0, -1] != word2idx['<EOS>']:\n",
    "        batch_logits = test_sess.run(\"decoder_lstm/decoder/transpose:0\",\n",
    "                       feed_dict = {\"encoder_inputs:0\": [ques],\n",
    "                                    \"decoder_inputs:0\": dec_input,\n",
    "                                    \"encoder_lengths:0\": [ques_len],\n",
    "                                    \"decoder_lengths:0\": dec_len,\n",
    "                                    \"batch_size:0\": bs})\n",
    "        prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "        dec_len[0] += 1\n",
    "\n",
    "        dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "\n",
    "    return dec_input[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dont run for demo\n",
    "# Testing\n",
    "test_batch_size = 40\n",
    "model = \"epoch20_2018-04-26_06:48:02\"\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('./mod_checkpoints/'+model+'.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./mod_checkpoints/'))\n",
    "    bleu_scores = []\n",
    "    for i, (source_batch, dec_batch_inputs, target_batch, enc_inp_lens, dec_inp_lens, target_w) in enumerate(tqdm(batch_data(test_X, test_Y, test_batch_size))):\n",
    "        for index, sample in enumerate(source_batch):\n",
    "            pred = test_sample(sess, sample, enc_inp_lens[index])\n",
    "\n",
    "            ip_str, ip_list = num2sent(sample, mode=\"i\", seq_len=enc_inp_lens[index])\n",
    "            target_str, target_list = num2sent(target_batch[index], mode=\"t\", seq_len=dec_inp_lens[index])\n",
    "            pred_str, pred_list = num2sent(pred, mode=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1064
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 54007,
     "status": "error",
     "timestamp": 1523866071342,
     "user": {
      "displayName": "Pritish Uplavikar",
      "photoUrl": "//lh6.googleusercontent.com/-7NiKMlDoOoA/AAAAAAAAAAI/AAAAAAAAHbQ/e6cUSH148VA/s50-c-k-no/photo.jpg",
      "userId": "103680692430921804968"
     },
     "user_tz": 300
    },
    "id": "alKt7mRO4gaM",
    "outputId": "b3fb3df5-49c0-47ca-e409-7026f7412931"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./mod_checkpoints/epoch20_2018-04-26_06:48:02\n",
      "Enter '!q' to quit\n",
      "User:\tWho are you ?\n",
      "Jarvis:\t nobody for now . : ) \n",
      "User:\tAre you a human or a robot ?\n",
      "Jarvis:\t i am a robot , but i have been programmed and trained to be anthropomorphic . \n",
      "User:\tWhat 's your name , Jarvis ?\n",
      "Jarvis:\t i am a robot , and i do n't have a family name . \n",
      "User:\twhat are your hobbies ?\n",
      "Jarvis:\t i like drawing and painting . \n",
      "User:\tWhat kind of music do you enjoy listening to ?\n",
      "Jarvis:\t i enjoy listening to interpret . \n",
      "User:\tIs it raining outside ?\n",
      "Jarvis:\t yes , it 's raining cats and dogs . \n",
      "User:\tWho taught you all these interesting stuff ?\n",
      "Jarvis:\t i am happy to hear what he is my father who teaches me every day . he is a software engineer who works all the time . \n",
      "User:\twho is your creator ?\n",
      "Jarvis:\t my father is a secret for now . : ) \n",
      "User:\tbye .\n",
      "Jarvis:\t thank you . \n",
      "User:\t!q\n"
     ]
    }
   ],
   "source": [
    "# Demo\n",
    "model = \"epoch20_2018-04-26_06:48:02\" # model trained for 20 epochs\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph('./mod_checkpoints/'+model+'.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('./mod_checkpoints/'))\n",
    "    print (\"Enter '!q' to quit\")\n",
    "    t = input(\"User:\\t\")\n",
    "    while t != \"!q\":\n",
    "        ip = t.lower().strip()\n",
    "        ip = ip.split()\n",
    "        for idx, word in enumerate(ip):\n",
    "            if word in word2idx:\n",
    "                ip[idx] = word2idx[word]\n",
    "            else:\n",
    "                ip[idx] = word2idx[\"<unk>\"]\n",
    "\n",
    "        ip += [word2idx['<EOS>']]\n",
    "        \n",
    "        predict = test_sample(sess, ip, len(ip))\n",
    "        prediction, _ = num2sent(predict, mode=\"r\")\n",
    "\n",
    "        print (\"Jarvis:\\t\", prediction)\n",
    "\n",
    "        t = input(\"User:\\t\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "chatbot.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
